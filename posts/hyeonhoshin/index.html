<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="theme" content="Chirpy v2.5.1"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Deep-Learning feature extractor&amp;descriptor based Visual Odometry" /><meta name="author" content="Hyeonho, Shin" /><meta property="og:locale" content="en_US" /><meta name="description" content="바라미의 블로그입니다." /><meta property="og:description" content="바라미의 블로그입니다." /><link rel="canonical" href="https://hyu-barami.github.io/posts/hyeonhoshin/" /><meta property="og:url" content="https://hyu-barami.github.io/posts/hyeonhoshin/" /><meta property="og:site_name" content="Barami" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-12-28T12:22:00+09:00" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"바라미의 블로그입니다.","@type":"BlogPosting","url":"https://hyu-barami.github.io/posts/hyeonhoshin/","headline":"Deep-Learning feature extractor&amp;descriptor based Visual Odometry","datePublished":"2020-12-28T12:22:00+09:00","dateModified":"2020-12-28T12:22:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://hyu-barami.github.io/posts/hyeonhoshin/"},"author":{"@type":"Person","name":"Hyeonho, Shin"},"@context":"https://schema.org"}</script><title>Deep-Learning feature extractor&descriptor based Visual Odometry | Barami</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/favicon.ico"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon.ico"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon.ico"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/favicon.ico"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="preload" href="/assets/css/barami.css" as="style"><link rel="stylesheet" href="/assets/css/barami.css"><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script async src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="/assets/js/post.min.js"></script> <script defer src="/app.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/barami.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Barami</a></div><div class="site-subtitle font-italic">한양대학교 학술동아리 바라미</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <span id="mode-toggle-wrapper"> <i class="mode-toggle fas fa-sun" dark-mode-invisible></i> <i class="mode-toggle fas fa-moon" light-mode-invisible></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.mode != null) { if (this.mode == ModeToggle.DARK_MODE) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.mode != null) { if (self.mode == ModeToggle.DARK_MODE) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span> <span class="icon-border"></span> <a href="https://github.com/ibarami" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Deep-Learning feature extractor&descriptor based Visual Odometry</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Deep-Learning feature extractor&descriptor based Visual Odometry</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Dec 28, 2020, 12:22 PM +0900" > Dec 28, 2020 <i class="unloaded">2020-12-28T12:22:00+09:00</i> </span> by <span class="author"> Hyeonho, Shin </span></div><div> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Dec 28, 2020, 1:18 PM +0900" > Dec 28, 2020 <i class="unloaded">2020-12-28T13:18:37+09:00</i> </span></div></div><div class="post-content"><hr /><h2 id="abstract">Abstract</h2><p>Welcome to brief description of DeepPoint VO, final assignment program designed by Hyeonho shin.</p><p>Our submitted program is designed to know to how much accuracy can be improved using the latest VO algorithms for beating SOTA in Visual monocular odometry algorithm, BVO[1].</p><p>To begin with, we implemented six algorithms and various parameters to compare. As a result, the key point algorithm was ‘LFNet’ with soft ratio-test.</p><p>Without additional training about KITTI dataset, our VO beats SOTA in median. Also we found the counter-well-known facts about ratio test.</p><p>Source code repository : <a href="https://github.com/hyeonhoshin/tanuki-pyslam">https://github.com/hyeonhoshin/tanuki-pyslam </a></p><h2 id="design">Design</h2><p>We reused the vanilla visual odometry framework except for Deep Learning based key point extractor and descriptor.</p><p>In detail, we used Brute Force feature matcher, because there is no elapsed time difference between FLANN matcher. Also, FLANN matcher has a danger to fall into local minima.</p><p>For reducing outliers of matching results, we used ratio test and RANSAC algorithm. The ratio test is similar to Voting algorithm. If 2nd good matching pair’s distance is too different with 1st one, we neglect this result. The RANSAC eliminates outliers, by probabilistic finding.</p><h2 id="experiment-condition">Experiment condition</h2><h3 id="hardware">Hardware</h3><ul><li>CPU : Intel Xeon Silver 4214<li>RAM : 256GB<li>Graphics : NVIDIA RTX2080ti</ul><h3 id="software">Software</h3><ul><li>Ubuntu 18.04 (20 not supported)<li>Bash shell<li>Anaconda</ul><h3 id="parameters">Parameters</h3><ul><li>Feature number limit : 1000<li>Ratio test coef : 0.99<li>Non maxima suppression radius : 7 pixels<li>No train with KITTI sets. Used the pretrained model.</ul><h2 id="result">Result</h2><h3 id="accuracy-comparison-among-key-point-algorithms">Accuracy comparison among Key point algorithms</h3><div class="table-wrapper"><table><tr><td><td>ORB2<td>DELF<td>R2D2<td>D2NET<td>LFNET<tr><td>Translation error(%)<td>16.80<td>83.09<td>1.06<td>1.69<td>0.68<tr><td>Rotation error(%)<td>5.49<td>37.18<td>0.41<td>0.70<td>0.59</table></div><p>With above table 1, we can see the LFNET has the best performance among the famous SOTA key point extraction and description algorithms.</p><h3 id="speed">Speed</h3><div class="table-wrapper"><table><tr><td>The number of features<td>100<td>250<td>500<td>1000<td>2000<td>3000<tr><td>Estimated FPS<td>31.16<td>25.95<td>18.72<td>13.69<td>8.81<td>3.70<tr><td>Translation error in Seq 07(%)<td>14.43<td>5.644<td>5.479<td>5.07<td>4.96<td>3.99</table></div><p>Because of the Python’s multi-thread limitation and IO bottleneck by using libraries(Torch-Caffe-NumPy), the total speed is under-estimated significantly. So we used the pre-made tool for estimating the FPS which considers feature key points extraction, description and matching. Because they take the most proportion of visual odometry, we thought it would be valid and reliable. We picked the key points 1000 only for analysis. Because it has more than 10FPS, which makes it possible to do real-time with KITTI’s dataset. The KITTI’s dataset has 10fps, and in the 1000 key points case the fps is higher than KITTI’s one.</p><h3 id="accuracy">Accuracy</h3><div class="table-wrapper"><table><tr><td>Trans err (%)<td>00<td>01<td>02<td>03<td>04<td>05<td>06<td>07<td>08<td>09<td>10<td>median<tr><td>Ours<td>1.15<td>3.72<td>1.90<td>0.86<td>1.32<td>0.68<td>5.07<td>1.75<td>1.39<td>0.85<td>1.32<td><tr><td>BVO<td>1.99<td>2.14<td>1.47<td>0.93<td>0.88<td>0.92<td>1.85<td>1.61<td>1.38<td>1.24<td>1.27<td>1.38</table></div><p>As you can see above table, we can beat the SOTA BVO in median. In detail, we beated BVO in sequece 00, 03, 04, 06, 10. Specifically, in 06, we can outperform 3 times in the error. On the other hand, we get the bad result in 07, about 5 times. Our analysis is guessed that our algorithm is more fragile to speed variation of the car. The sequence 06 keep speed consistently, but luminance change is large. In contract, in sequence 07, speed change is more variant. It includes waiting, stopping, accelearating, slowing.</p><h2 id="conclusion">Conclusion</h2><p>In this project, we designed the visual odometry algorithm assisted by Deep-Learning based Key point detection and description. And it outperforms in some sequences by accuracy without additional traing about KITTI dataset. What we revealed in this project is the fact that ratio test is needed for implementing VO. By many authors including LFNet’s authors, without ratio test, the VO’s stablity is degraded. And by trials and errors, we present our the best parameter for ratio test also. The best results occurs at 0.99. In addition, we revealed the fact that do not set scale factor. That makes the Neural Networks distribution, and make degradation for it. Also among 6 SoTA Kp detection &amp; description(LFNet, D2Net, SuperPoint, R2D2, DELF), The best performance algorithm is <strong>LFNet</strong>. But the fastest algorithm with reasonable performance is SuperPoint.</p><h2 id="how-to-set-pre-requisites">How to set Pre-requisites</h2><p>Because our alogrithms depends on a lot of external library. I’ll give you a program which can make same environments wit ours.</p><ul><li>Install anaconda (https://www.anaconda.com/products/individual)<li>Download our program using git recursively ( “git clone –recursive https://github.com/hyeonhoshin/tanuki-pyslam”, because it needs to download sub-libraries )<li>Change directory to the downloaded ‘tanuki-pyslam’<li>In terminal at the ‘~’ directory, type “. install_all_conda.sh”<li>If the setting program demands the sudo password, type it.<li>All done.</ul><h2 id="how-to-run-our-program">How to run our program</h2><ul><li>Change directory into ‘tanuki-pyslam’<li>Activate virtual Python environment by typing ‘conda activate pyslam’<li>Input your dataset directory and output directory in config.ini (In KITTI dataset, base_path=/home/user/……/dataset, output_path=/as/you/want but in default the results are recorded in outputs folder)<li>Specify which sequence to test in config.ini (For example, name=06 means 6th sequence in KITTI set)<li>Execute our program by typing ‘python main_vo.py’<li>Check the generated file “XX.txt” which includes R, t</ul><h2 id="how-to-see-real-time-progress">How to see real-time progress</h2><p>If you want to see real-time progress same as included video file, just modify gui_on as True. But, if you cannot use Monitor, it makes our code do not operate.</p><h2 id="how-to-evaluate-my-program">How to evaluate my program</h2><ul><li>Change directory into ‘~’<li>Clone the KITTI Visual odometry evaluation tool by typing “git clone https://github.com/Huangying-Zhan/kitti-odom-eval”<li>Change directory to the cloned directory, by typing “cd kitti-odom-eval”<li>For installing dependencies, type “conda env create -f requirement.yml –n kitti_eval”<li>Activate the installed virtual environment by typing, “conda activate kitti_eval”<li>For executing the evaluation program, type “python eval_odom.py —result RESULT_PATH”, which includes result files from the step of “How to run our program”</ul><h2 id="references">References</h2><p>[1] Fabio Irigon Pereira, 2017 Workshop of Computer Vision, “Backward Motion for Estimation Enhancement in Sparse Visual Odometry” [2] Y. Ono, E. Trulls, P. Fua, K.M. Yi, “LF-Net: Learning Local Features from Images” [3] Luigifreda, github, Pyslam, https://github.com/luigifreda/pyslam. [4] Dusmanu, CVPR 2019, “D2-Net: A Trainable CNN for Joint Detection and Description of Local Features” [5] Axel Barroso-Laguna, ICCV 2019, “Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters“ [6] Zhan, arXiv 2019, “Visual Odometry Revisited: What Should Be Learnt?”</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/exhibition/'>Exhibition</a>, <a href='/categories/2020%EB%85%84/'>2020년</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/post/" class="post-tag no-text-decoration" >post</a> <a href="/tags/hyeonho-shin/" class="post-tag no-text-decoration" >hyeonho-shin</a> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >deep-learning</a> <a href="/tags/computer-science/" class="post-tag no-text-decoration" >computer-science</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Deep-Learning feature extractor&descriptor based Visual Odometry - Barami&url=https://hyu-barami.github.io/posts/hyeonhoshin/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Deep-Learning feature extractor&descriptor based Visual Odometry - Barami&u=https://hyu-barami.github.io/posts/hyeonhoshin/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Deep-Learning feature extractor&descriptor based Visual Odometry - Barami&url=https://hyu-barami.github.io/posts/hyeonhoshin/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/portable_braille_voice_translator/">휴대용 점자 음성 번역기</a><li><a href="/posts/GPS-L1-MSA/">빔폭 향상을 위한 모드합성 안테나</a><li><a href="/posts/endurance_drone/">곤충 시각 기관 모방 센서와 인공신경망을 적용한 실내 드론 시스템</a><li><a href="/posts/pythongame/">Pythongame</a><li><a href="/posts/Detachable-lost-and-found-system/">탈부착형 분실물 찾기 시스템</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/post/">post</a> <a class="post-tag" href="/tags/shinhyun/">shinhyun</a> <a class="post-tag" href="/tags/hwanghyeonjo/">hwanghyeonjo</a> <a class="post-tag" href="/tags/opencv/">opencv</a> <a class="post-tag" href="/tags/ahndongkun/">ahndongkun</a> <a class="post-tag" href="/tags/ai/">ai</a> <a class="post-tag" href="/tags/analog-circuit/">analog circuit</a> <a class="post-tag" href="/tags/arduino/">arduino</a> <a class="post-tag" href="/tags/arm/">arm</a> <a class="post-tag" href="/tags/blynk/">blynk</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div><div class="custom-panel"><div class="custom-panel-title"> 2021년 바라미 전시회</div><div class="custom-panel-content"> <a href="/categories/2021년"> ❯ 작품 목록 보기</a></div><div class="custom-panel-content"> <a herf="#"> ❯ 방명록 작성하기 (12월 1일 자정부터 링크 열립니다.)</a></div></div><div class="custom-panel"><div class="custom-panel-title"> 바라미 후원하기</div><div class="custom-panel-content"> 신한은행 100-028-832805 바라미</div></div><div class="custom-panel"><div class="custom-panel-title"> 역대 전시회 목록</div><div class="custom-panel-content"> <a href="/categories/2021년"> ❯ 2021년 전시회</a></div><div class="custom-panel-content"> <a href="/categories/2020년"> ❯ 2020년 전시회</a></div></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/25th-kimjeonghyun-jinwonbot/"><div class="card-body"> <span class="timeago small" > Dec 25, 2020 <i class="unloaded">2020-12-25T22:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>진원봇-바라미실 문 개폐 알림 봇</h3><div class="text-muted small"><p> 진원봇 : 바라미실 문 개폐 알림 봇 진원봇(jinwonbot)은 바라미실 문 개폐 여부를 원격지에서 확인할 수 있는 채팅 봇입니다. 개발 동기 바라미실의 출입문이 열려있는지의 여부는 준회원의 동아리실 출입을 도와주거나 재실 인원이 있는지 확인하기 위해 지속적인 수요가 존재해왔습니다. 이 때문에 이전부터 바라미캠(2016, 송유진) 과 바라미는 열렸...</p></div></div></a></div><div class="card"> <a href="/posts/cam-fpga/"><div class="card-body"> <span class="timeago small" > Dec 27, 2020 <i class="unloaded">2020-12-27T03:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>방범용 감시장치(FPGA를 이용한)</h3><div class="text-muted small"><p> #프로젝트 현황 현재 주제 난이도 선정 실패와 레퍼런스의 부족 등으로 인해 프로젝트 진행에 어려움을 겪고 있습니다. 27일 업로드는 (부분적으로라도) 불가능할 것으로 보입니다. 저희 프로젝트 결과를 기대하고 보러 들어오셨던 분들께는 죄송합니다. 현재는 총회 이전 완성을 목표로 하고 있습니다.</p></div></div></a></div><div class="card"> <a href="/posts/yonghui-yun/"><div class="card-body"> <span class="timeago small" > Dec 27, 2020 <i class="unloaded">2020-12-27T13:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Analog Circuit Design - Operational Amplifier</h3><div class="text-muted small"><p> 위 그림에는 하나의 OPAMP를 구동하기 위한 모든 회로가 들어가 있습니다. 수학 표현식의 문제때문에 설명문을 제 github에 따로 업로드 하였습니다. 양해부탁드립니다 ㅠㅠ 설명 보러 가기 [주의: 지루할 수 있음]</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/yonghui-yun/" class="btn btn-outline-primary"><p>Analog Circuit Design - Operational Amplifier</p></a> <a href="/posts/guest-book/" class="btn btn-outline-primary"><p>2020년 바라미 전시회 방명록 (추첨 1분 선물 증정)</p></a></div><script src="https://utteranc.es/client.js" repo="hyu-barami/hyu-blog-comment" issue-term="pathname" label="comment" theme="github-light" crossorigin="anonymous" async> </script></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://github.com/ibarami">Barami</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/post/">post</a> <a class="post-tag" href="/tags/shinhyun/">shinhyun</a> <a class="post-tag" href="/tags/hwanghyeonjo/">hwanghyeonjo</a> <a class="post-tag" href="/tags/opencv/">opencv</a> <a class="post-tag" href="/tags/ahndongkun/">ahndongkun</a> <a class="post-tag" href="/tags/ai/">ai</a> <a class="post-tag" href="/tags/analog-circuit/">analog circuit</a> <a class="post-tag" href="/tags/arduino/">arduino</a> <a class="post-tag" href="/tags/arm/">arm</a> <a class="post-tag" href="/tags/blynk/">blynk</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://hyu-barami.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); </script>
